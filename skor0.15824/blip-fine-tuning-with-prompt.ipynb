{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":101408,"databundleVersionId":12268213,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\nfrom transformers import BlipProcessor, BlipForConditionalGeneration, TrainingArguments, Trainer, EarlyStoppingCallback","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T15:41:53.365848Z","iopub.execute_input":"2025-05-24T15:41:53.366130Z","iopub.status.idle":"2025-05-24T15:42:23.670365Z","shell.execute_reply.started":"2025-05-24T15:41:53.366094Z","shell.execute_reply":"2025-05-24T15:42:23.669802Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ------------------------ Dataset ------------------------ #\nclass ImageCaptionDataset(Dataset):\n    def __init__(self, dataframe, image_folder, processor):\n        self.dataframe = dataframe.reset_index(drop=True)\n        self.image_folder = image_folder\n        self.processor = processor\n\n        # Veri augmentasyonu (BLIP varsayılan 384x384, augmentasyonlar eklendi)\n        self.transform = transforms.Compose([\n            transforms.Resize((384, 384)),\n            transforms.RandomHorizontalFlip(),\n            transforms.ColorJitter(brightness=0.1, contrast=0.1),\n            transforms.ToTensor(),\n        ])\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        row = self.dataframe.iloc[idx]\n        img_name = str(row['image_id']) + \".jpg\"\n        img_path = os.path.join(self.image_folder, img_name)\n        caption = row['caption']\n        image = Image.open(img_path).convert(\"RGB\")\n\n        # Transform uygulanıyor\n        image = self.transform(image)\n        # PIL Image yerine Tensor ile processor çağırmak için tekrar Image'a çevirebiliriz,\n        # ancak BLIP processor tensor veya PIL kabul ediyor, eğer problem çıkarsa aşağıdaki yorum satırını kullanabilirsin:\n        # image = transforms.ToPILImage()(image)\n\n        # Prompt çeşitlendirme\n        text = random.choice([\n            caption,\n            f\"A picture showing {caption}\",\n            f\"This image describes: {caption}\",\n            f\"A photo of {caption}\",\n            f\"An image that illustrates {caption}\"\n        ])\n\n        inputs = self.processor(\n            images=image,\n            text=text,\n            return_tensors=\"pt\",\n            padding=\"max_length\",\n            truncation=True,\n            max_length=128,\n        )\n        # Loss için etiketler\n        inputs['labels'] = inputs['input_ids']\n        inputs = {k: v.squeeze(0) for k, v in inputs.items()}\n        return inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T15:43:40.929357Z","iopub.execute_input":"2025-05-24T15:43:40.930569Z","iopub.status.idle":"2025-05-24T15:43:40.938238Z","shell.execute_reply.started":"2025-05-24T15:43:40.930538Z","shell.execute_reply":"2025-05-24T15:43:40.937341Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ------------------------ Ayarlar ve Yollar ------------------------ #\ntrain_csv = '/kaggle/input/obss-intern-competition-2025/train.csv'\ntrain_images = '/kaggle/input/obss-intern-competition-2025/train/train/'\ntest_csv = '/kaggle/input/obss-intern-competition-2025/test.csv'\ntest_images = '/kaggle/input/obss-intern-competition-2025/test/test/'\nsave_path = '/kaggle/working/blip-finetuned'\n\nfrom transformers import BlipProcessor, BlipForConditionalGeneration\n\nprocessor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\nmodel = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n\n\n# ------------------------ Veri Okuma ve Temizlik ------------------------ #\ndf = pd.read_csv(train_csv)\n\n# Caption temizliği: \ndf['caption'] = df['caption'].str.strip().str.replace(r'[^\\w\\s]', '', regex=True)  # noktalama işaretlerini kaldır\ndf = df[df['caption'].str.split().str.len().between(5, 50)]  # 5-50 kelime arası caption'lar kalır\n\n# Eğitim / validasyon split\ntrain_df, val_df = train_test_split(df, test_size=0.1, random_state=42)\n\ntrain_dataset = ImageCaptionDataset(train_df, train_images, processor)\nval_dataset = ImageCaptionDataset(val_df, train_images, processor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T15:44:14.511699Z","iopub.execute_input":"2025-05-24T15:44:14.512018Z","iopub.status.idle":"2025-05-24T15:44:21.877570Z","shell.execute_reply.started":"2025-05-24T15:44:14.511997Z","shell.execute_reply":"2025-05-24T15:44:21.876944Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ------------------------ Eğitim Ayarları ------------------------ #\ntraining_args = TrainingArguments(\n    output_dir=save_path,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,  \n    num_train_epochs=3,\n    save_total_limit=1,\n    save_steps = len(train_dataset),\n    learning_rate=5e-5,\n    warmup_steps=500,\n    weight_decay=0.01,\n    fp16=True,\n    logging_dir=f\"{save_path}/logs\",\n    logging_steps=10,\n    report_to=\"none\",\n)\n\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n)\n\ntrainer.train()\n\nmodel.save_pretrained(save_path)\nprocessor.save_pretrained(save_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T15:46:57.312014Z","iopub.execute_input":"2025-05-24T15:46:57.312957Z","iopub.status.idle":"2025-05-24T18:01:46.717496Z","shell.execute_reply.started":"2025-05-24T15:46:57.312918Z","shell.execute_reply":"2025-05-24T18:01:46.716334Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save_pretrained(save_path)\nprocessor.save_pretrained(save_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T18:02:45.419721Z","iopub.execute_input":"2025-05-24T18:02:45.420415Z","iopub.status.idle":"2025-05-24T18:02:47.492865Z","shell.execute_reply.started":"2025-05-24T18:02:45.420377Z","shell.execute_reply":"2025-05-24T18:02:47.492245Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ------------------------ Caption Üretimi ------------------------ #\ntest_df = pd.read_csv(test_csv)\ntest_df[\"image_id\"] = test_df[\"image_id\"].astype(str)\n\ncaption_model = BlipForConditionalGeneration.from_pretrained(save_path)\ncaption_processor = BlipProcessor.from_pretrained(save_path)\ncaption_model.eval()\n\ncaptions = []\n\nprint(\"Caption üretimi başlıyor...\")\nfor _, row in tqdm(test_df.iterrows(), total=len(test_df)):\n    image_path = os.path.join(test_images, str(row[\"image_id\"]) + \".jpg\")\n    image = Image.open(image_path).convert(\"RGB\")\n    \n    inputs = caption_processor(image, return_tensors=\"pt\")\n\n    with torch.no_grad():\n        output = caption_model.generate(\n            **inputs,\n            max_length=128,\n            num_beams=5,           # Beam search ile daha kaliteli captionlar\n            no_repeat_ngram_size=2,\n            early_stopping=True\n        )\n\n    caption = caption_processor.decode(output[0], skip_special_tokens=True)\n    captions.append(caption)\n\nsubmission_df = pd.DataFrame({\n    \"image_id\": test_df[\"image_id\"],\n    \"caption\": captions\n})\nsubmission_df.to_csv(\"/kaggle/working/submission.csv\", index=False)\nprint(\"Captionlar başarıyla kaydedildi!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T18:10:35.647706Z","iopub.execute_input":"2025-05-24T18:10:35.648280Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Caption üretimi başlıyor...\n100%|██████████| 3771/3771 [11:44:07<00:00, 11.20s/it]   ","metadata":{}},{"cell_type":"markdown","source":"submission.csv\n\nSkor: 0.15824","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}